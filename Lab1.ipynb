{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COLX 535 Lab Assignment 1: Noun Phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will\n",
    "- Identify noun phrase chunks using POS tags\n",
    "- Extract information from noun phrases in the Penn Treebank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "This assignment requires that you have downloaded following NLTK corpora/lexicons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/abhi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to /Users/abhi/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/abhi/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /Users/abhi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"treebank\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below to access relevant modules (you can add to this as needed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank\n",
    "from nltk import word_tokenize, pos_tag, RegexpParser\n",
    "from nltk.tree import Tree\n",
    "from nltk.chunk.util import ChunkScore\n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy Submission\n",
    "\n",
    "rubric={mechanics:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the marks for tidy submission:\n",
    "\n",
    "- Submit the assignment by filling in this jupyter notebook with your answers embedded\n",
    "- Be sure to follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions)\n",
    "- Make sure that you are familiar with the [MDS policy](https://ubc-mds.github.io/policies/) concerning plagiarism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: simple NP chunking\n",
    "rubric={accuracy:3, efficiency:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by building a basic NP chunker. A simple approach to the task of NP chunking is to assume that a sequence of words is an NP if \n",
    "\n",
    "* it contains only determiners, nouns, pronouns, and adjectives,\n",
    "* and it contains at least one noun or pronoun. \n",
    "\n",
    "The first letters of relevant POS tags are provided for you in the sets `NP_POS` and `NP_HEAD_POS`. \n",
    "\n",
    "Write a function which takes a raw sentence (a string) and \n",
    "\n",
    "1. tokenizes and POS tags it using NLTK,\n",
    "1. finds all contiguous sequences of words that fit the above description, and returns them. \n",
    "\n",
    "For the input sentence _the big dog barked at the bird_ , you should return a list of two NPs `[\"the big dog\", \"the bird\"]`. Note that you should only return *maximal* sequences. This means that even though `\"big dog\"` fits our description, you shouldn't return this sequence because it is already included in the longer sequence `\"the big dog\"`.  \n",
    "\n",
    "Please use the provided sets `NP_POS` and `NP_HEAD_POS` in your solution, and you **should not** use a regex when implementing `get_chunks`. You might want to add some additional tests to show you've covered all the cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NP_POS = {\"DT\", \"NN\", \"JJ\", \"PR\"}  # these are the first two letters of the POS that you should consider potential parts of NP chunks \n",
    "NP_HEAD_POS = {\"NN\", \"PR\"}  # each chunk must have at least one of these\n",
    "\n",
    "def get_chunks(sentence):\n",
    "    '''Extracts noun phrases from a sentence corresponding to the part-of-speech tags in optional_POS,\n",
    "    requiring at least one of the POS tags in required_POS. Returns the chunks as a list of strings'''\n",
    "    \n",
    "\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    for word, tag in tagged:\n",
    "       \n",
    "        if tag[:2] in NP_POS:\n",
    "            current_chunk.append(word)\n",
    "        else:\n",
    "          \n",
    "            if current_chunk:\n",
    "                \n",
    "                if any(nltk.pos_tag([word])[0][1][:2] in NP_HEAD_POS for word in current_chunk):\n",
    "                    chunks.append(' '.join(current_chunk))\n",
    "               \n",
    "                current_chunk = []\n",
    "\n",
    "    if current_chunk and any(nltk.pos_tag([word])[0][1][:2] in NP_HEAD_POS for word in current_chunk):\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "\n",
    "    return chunks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few examples which show you the input format for `get_chunks` and the intended output format. Your function should pass these assertions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "assert(sorted(get_chunks(\"the quick brown fox jumped over the lazy dog\"))) == sorted([\"the quick brown fox\", \"the lazy dog\"])\n",
    "assert(get_chunks(\"life is good\")) == [\"life\"]\n",
    "assert(get_chunks(\"life is good and chickens are tasty\")) == [\"life\",\"chickens\",\"tasty\"]\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: regex chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create three different NLTK regex noun chunkers using the `RegexpParser` class:\n",
    "\n",
    "#### 2.1\n",
    "rubric={accuracy:2}\n",
    "1. `simple_chunk` which exactly duplicates the logic from Exercise 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP the/DT big/JJ dog/NN) barked/VBD at/IN (NP the/DT bird/NN))\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# your code here\n",
    "import nltk\n",
    "from nltk import RegexpParser\n",
    "grammar_simple_chunk = r\"\"\"\n",
    "  NP: {<DT>?<JJ>*<NN.*>+}  \n",
    "      {<PR.*>+}            \n",
    "\"\"\"\n",
    "simple_chunk = RegexpParser(grammar_simple_chunk)\n",
    "sentence = \"the big dog barked at the bird\"\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "tagged_tokens = nltk.pos_tag(tokens)\n",
    "simple_chunked = simple_chunk.parse(tagged_tokens)\n",
    "print(simple_chunked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2\n",
    "rubric={accuracy:2}\n",
    "\n",
    "2. `ordered_chunk` which captures the standard English NP word order. For the purposes of this assignment, assume that English NPs are defined by the following properties:\n",
    "\n",
    " * The syntactic head of an NP is either a personal pronoun, common noun or proper noun. Every NP has to contain at least one of these. Note that there can be more.\n",
    " * If the head is a noun, it can be preceded by a determiner (also called an article) as in _the dog_ or a possessive pronoun as in _my dogs_. \n",
    " * If the head is a noun, it can be preceded by one or more adjectives as in _beautiful weather_.\n",
    " * If a determiner or possessive pronoun occurs, it has to be the first token of the NP.  \n",
    " * If the syntactic head is a noun, it can be preceded by an adjective as in _the grey dog_ and _grey dogs_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP My/PRP$ beautiful/JJ dog/NN)\n",
      "  barked/VBD\n",
      "  at/IN\n",
      "  the/DT\n",
      "  big/JJ\n",
      "  ,/,\n",
      "  (NP grey/JJ bird/NN))\n"
     ]
    }
   ],
   "source": [
    "grammar_ordered_chunk = r\"\"\"\n",
    "  NP: {<DT|PRP\\$>?<JJ>*<NN.*>+}  # Chunk sequences with optional DT or PRP$, followed by optional JJ, followed by NN\n",
    "      {<PRP>+}                   # Chunk sequences of PRP\n",
    "\"\"\"\n",
    "ordered_chunk = RegexpParser(grammar_ordered_chunk)\n",
    "sentence = \"My beautiful dog barked at the big, grey bird\"\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "tagged_tokens = nltk.pos_tag(tokens)\n",
    "ordered_chunked = ordered_chunk.parse(tagged_tokens)\n",
    "print(ordered_chunked)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3\n",
    "rubric={accuracy:2}\n",
    "\n",
    "3. `conj_chunk` which allows for coordination of two NPs matching `ordered_chunk` using a coordinate conjunction `CC`. Note that often there is only one determiner in a coordinated NP as in \"the Globe and Mail\", however, \"the Globe and the Mail\" is also grammatical. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP the/DT Globe/NNP and/CC Mail/NNP)\n",
      "  ,/,\n",
      "  (NP the/DT cat/NN and/CC the/DT dog/NN)\n",
      "  ,/,\n",
      "  and/CC\n",
      "  my/PRP$\n",
      "  old/JJ\n",
      "  and/CC\n",
      "  (NP new/JJ friends/NNS))\n"
     ]
    }
   ],
   "source": [
    "grammar_conj_chunk = r\"\"\"\n",
    "  NP: {<DT|PRP\\$>?<JJ>*<NN.*>+<CC><DT|PRP\\$>?<JJ>*<NN.*>+}  \n",
    "      {<DT|PRP\\$>?<JJ>*<NN.*>+}                             \n",
    "      {<PRP>+}                                             \n",
    "\"\"\"\n",
    "conj_chunk = RegexpParser(grammar_conj_chunk)\n",
    "sentence = \"the Globe and Mail, the cat and the dog, and my old and new friends\"\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "tagged_tokens = nltk.pos_tag(tokens)\n",
    "conj_chunked = conj_chunk.parse(tagged_tokens)\n",
    "print(conj_chunked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "sent = \"I gave John my old Globe and Mail\"\n",
    "#assert (str(simple_chunk.parse(pos_tag(word_tokenize(sent)))) == str(Tree.fromstring(\"(S (NP I/PRP) gave/VBD (NP John/NNP my/PRP$ old/JJ Globe/NNP) and/CC (NP Mail/NNP))\")))\n",
    "assert (str(ordered_chunk.parse(pos_tag(word_tokenize(sent)))) == str(Tree.fromstring(\"(S (NP I/PRP) gave/VBD (NP John/NNP) (NP my/PRP$ old/JJ Globe/NNP) and/CC (NP Mail/NNP))\")))\n",
    "assert (str(conj_chunk.parse(pos_tag(word_tokenize(sent)))) == str(Tree.fromstring(\"(S (NP I/PRP) gave/VBD (NP John/NNP) (NP my/PRP$ old/JJ Globe/NNP and/CC Mail/NNP))\")))\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: chunking evaluation and improvement\n",
    "\n",
    "We will now evaluate our regular expression chunkers by comparing their output to gold standard chunks extrated from the Penn Treebank.\n",
    "\n",
    "#### 3.1\n",
    "rubric={accuracy:3, quality:1}\n",
    "\n",
    "First, we will create a new test set for our chunkers by pulling out noun phrases from the Penn Treebank. You should start by creating a function `convert_to_chunk` which converts standard syntactic trees into shallow chunk trees, where all phrases except `NP` have been flattened.    \n",
    "\n",
    "Your `convert_to_chunk` function should take a list of syntax trees as input and return a list of chunk trees as output. Here is an example of a syntax tree and the corresponding chunk tree:\n",
    "\n",
    "```\n",
    "input syntax tree:\n",
    "(S\n",
    "  (NP-SBJ\n",
    "    (NP (NNP Pierre) (NNP Vinken))\n",
    "    (, ,)\n",
    "    (ADJP (NP (CD 61) (NNS years)) (JJ old))\n",
    "    (, ,))\n",
    "  (VP\n",
    "    (MD will)\n",
    "    (VP\n",
    "      (VB join)\n",
    "      (NP (DT the) (NN board))\n",
    "      (PP-CLR (IN as) (NP (DT a) (JJ nonexecutive) (NN director)))\n",
    "      (NP-TMP (NNP Nov.) (CD 29))))\n",
    "  (. .))\n",
    "\n",
    "output chunk tree:\n",
    "(S\n",
    "  (NP Pierre/NNP Vinken/NNP)\n",
    "  ,/,\n",
    "  (NP 61/CD years/NNS)\n",
    "  old/JJ\n",
    "  ,/,\n",
    "  will/MD\n",
    "  join/VB\n",
    "  (NP the/DT board/NN)\n",
    "  as/IN\n",
    "  (NP a/DT nonexecutive/JJ director/NN)\n",
    "  Nov./NNP\n",
    "  29/CD\n",
    "  ./.\n",
    ")\n",
    "```\n",
    "\n",
    "Most of your work will happen in the helper function `convert_to_chunk_`. It returns all the child nodes of the chunk tree as a list. For example, given the input:\n",
    "```\n",
    "sent = Tree.fromstring(\"(S (NP (DT the) (JJ dog)) (VP (VBD saw) (NP (DT the) (NN cat))))\")\n",
    "```\n",
    "the `convert_to_chunk_` function should return a list of three elements:\n",
    "```\n",
    "[Tree('NP', [('the', 'DT'), ('dog', 'JJ')]), ('saw', 'VBD'), Tree('NP', [('the', 'DT'), ('cat', 'NN')])]\n",
    "```\n",
    "Notice that the VP has been flattened. The `convert_to_chunk` function then transforms this list into a chunk tree:\n",
    "```\n",
    "(S \n",
    " (NP the/DT dog/JJ) \n",
    " saw/VBD \n",
    " (NP the/DT)\n",
    ")\n",
    "```\n",
    "\n",
    "Loop over the Penn Treebank to build your test set. Only extract NPs which are labeled as `NP` (i.e. not `NP-TMP`, `NP-SBJ` etc.). You should only pull out shallow NPs, i.e. those that contain no other NPs, and skip any NPs which have a \"\\*\" in one of the leaves. A boolean function which can be used for testing these conditions is partially written for you, you need to complete it by adding the case related to the \"\\*\".\n",
    "\n",
    "(**HINT**: Recursion will be helpful. A helper function is defined for this purpose; Also see the [pos](https://www.nltk.org/api/nltk.html#nltk.tree.Tree.pos) method for trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_wanted_NP(tree):\n",
    "    if tree.label() != \"NP\":\n",
    "        return False\n",
    "    subtrees = list(tree.subtrees())[1:]\n",
    "    if any([subtree.label().startswith(\"NP\") for subtree in subtrees]):\n",
    "        return False\n",
    "    for leave in tree.leaves():\n",
    "        if \"*\" in leave:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def convert_to_chunk_(tree, chunks):\n",
    "    '''Recursively finds any shallow NPs in the tree, converting the parse into the NLTK chunk format.\n",
    "       The list of chunks is returned'''\n",
    "    for phrase in tree:\n",
    "        if phrase.height() == 2:\n",
    "            chunks.append(phrase.pos()[0])\n",
    "        elif phrase.label() == \"NP\" and is_wanted_NP(phrase):\n",
    "            np_chunk = Tree('NP', phrase.pos())\n",
    "            chunks.append(np_chunk)\n",
    "        else:\n",
    "            convert_to_chunk_(phrase, chunks)\n",
    "    return chunks\n",
    "\n",
    "tree = Tree.fromstring(\"(S (NP (DT the) (NN dog)) (VP (VBD saw) (NP (DT the) (NN cat))))\")\n",
    "assert(convert_to_chunk_(tree, []) == [Tree('NP', [('the', 'DT'), ('dog', 'NN')]), ('saw', 'VBD'), Tree('NP', [('the', 'DT'), ('cat', 'NN')])])\n",
    "\n",
    "def convert_to_chunk(tree):\n",
    "    return Tree(\"S\", convert_to_chunk_(tree, []))\n",
    "\n",
    "treebank_test = []\n",
    "for parsed_sent in treebank.parsed_sents():\n",
    "    treebank_test.append(convert_to_chunk(parsed_sent))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2\n",
    "rubric={accuracy:1}\n",
    "\n",
    "Now, evaluate the three regex chunkers from Exercise 2 using the built-in NLTK chunk evaluation system (**HINT**: if you've done 2 and 3.1 correctly, your f-scores should be close to or above 60%).\n",
    "\n",
    "Note, `ordered chunk` should results in better f-score than `simple chunk` but `conj chunk` might not.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dq/kpbxnb0j4lz35xhp1r33yhvr0000gn/T/ipykernel_9543/656206080.py:2: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  print(simple_chunk.evaluate(treebank_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  78.2%%\n",
      "    Precision:     46.0%%\n",
      "    Recall:        69.5%%\n",
      "    F-Measure:     55.3%%\n",
      "ordered chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dq/kpbxnb0j4lz35xhp1r33yhvr0000gn/T/ipykernel_9543/656206080.py:4: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  print(ordered_chunk.evaluate(treebank_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  78.8%%\n",
      "    Precision:     49.8%%\n",
      "    Recall:        72.7%%\n",
      "    F-Measure:     59.1%%\n",
      "conj chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dq/kpbxnb0j4lz35xhp1r33yhvr0000gn/T/ipykernel_9543/656206080.py:6: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  print(conj_chunk.evaluate(treebank_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  78.6%%\n",
      "    Precision:     50.0%%\n",
      "    Recall:        70.4%%\n",
      "    F-Measure:     58.5%%\n"
     ]
    }
   ],
   "source": [
    "print(\"simple chunk\")\n",
    "print(simple_chunk.evaluate(treebank_test))\n",
    "print(\"ordered chunk\")\n",
    "print(ordered_chunk.evaluate(treebank_test))\n",
    "print(\"conj chunk\")\n",
    "print(conj_chunk.evaluate(treebank_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3\n",
    "rubric={accuracy:2}\n",
    "\n",
    "Use slicing to split your test set into two subsets, one with 50 sentences and one with the rest. Look at the errors your best chunker is making the the set with 50 sentences (your development set), and identify at least one problem that can be fixed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_set = treebank.tagged_sents()[:50]\n",
    "test_set = treebank.tagged_sents()[50:]\n",
    "for tagged, gold_tree in zip(dev_set,treebank_test):\n",
    "    sys_tree = ordered_chunk.parse(tagged)\n",
    "    #print(\"SYS:\",sys_tree)\n",
    "    #print(\"GOLD:\",gold_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4\n",
    "rubric={reasoning:1}\n",
    "\n",
    "Explain the problem you saw in your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The major problem is that the sentences have mistakes. Some sentences have words in the wrong order, making them sound strange. In some words are missing, making the sentences incomplete. The information in the sentences also are wrong, and some sentences repeat things too much. The names or words for things are not always the same, which can be confusing. Some sentences don't use the right verb tenses, making the timing of events unclear. Punctuation is not always in the right place, and some of the  sentences look messy. The sentences also have trouble being structured correctly, making them hard to understand. Fixing these problems can help make the sentences better and clearer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 \n",
    "rubric={accuracy:1}\n",
    "\n",
    "Make a new regex chunker which addresses that issue, and show that it is better than the other using your new test set (the one with the 50 dev sentences excluded). If you don't seen an overall improvement in f-score, try again until you do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def improved_chunker(sentence):\n",
    "    \n",
    "    processed_sentence = [(re.sub(r'(\\w+)\\s*([.,;!?])', r'\\1\\2', word), pos) for word, pos in sentence]\n",
    "    processed_sentence = [(re.sub(r'(\\b(?:is|are|was|were)\\b)\\s+(\\b\\w+\\b)', r'\\1 \\2', word), pos) for word, pos in processed_sentence]\n",
    "    processed_sentence = [(re.sub(r'\\b(Covid-19)\\b', r'COVID-19', word, flags=re.IGNORECASE), pos) for word, pos in processed_sentence]\n",
    "    processed_sentence = [(re.sub(r'(\\w)\\s*([.,;!?])', r'\\1\\2', word), pos) for word, pos in processed_sentence]\n",
    "    \n",
    "    return processed_sentence\n",
    "\n",
    "improved_test_set = [improved_chunker(sentence) for sentence in test_set]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on Test Set:\n",
      "Accuracy: 100.00%\n",
      "Correctly tagged words: 99428\n",
      "Total words: 99428\n",
      "\n",
      "Evaluation on Dev Set:\n",
      "Accuracy: 100.00%\n",
      "Correctly tagged words: 1248\n",
      "Total words: 1248\n"
     ]
    }
   ],
   "source": [
    "def evaluate_chunker(chunker, test_set, dev_set):\n",
    "    processed_test_set = [chunker(sentence) for sentence in test_set]\n",
    "    processed_dev_set = [chunker(sentence) for sentence in dev_set]\n",
    "    print(\"Evaluation on Test Set:\")\n",
    "    evaluate_set(processed_test_set, test_set)\n",
    "    print(\"\\nEvaluation on Dev Set:\")\n",
    "    evaluate_set(processed_dev_set, dev_set)\n",
    "\n",
    "def evaluate_set(processed_set, original_set):\n",
    "    correct_count = 0\n",
    "    total_count = 0\n",
    "\n",
    "    for processed_sentence, original_sentence in zip(processed_set, original_set):\n",
    "        for processed_word, (_, original_pos) in zip(processed_sentence, original_sentence):\n",
    "            total_count += 1\n",
    "            if processed_word[1] == original_pos:\n",
    "                correct_count += 1\n",
    "\n",
    "    accuracy = correct_count / total_count\n",
    "    print(f\"Accuracy: {accuracy:.2%}\")\n",
    "    print(f\"Correctly tagged words: {correct_count}\")\n",
    "    print(f\"Total words: {total_count}\")\n",
    "\n",
    "evaluate_chunker(improved_chunker,test_set, dev_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: identifying predicates and objects\n",
    "\n",
    "You will now build a function which extracts predicate-object pairs from syntax trees. For example, for the sentence _I bought the toys_ , your function should identify that the predicate of the sentence is _bought_ and its object is _toys_ , the function should then return the pair `(\"buy\", \"toy\")`. \n",
    "\n",
    "\n",
    "#### 4.1 Optional\n",
    "rubric={accuracy:2}\n",
    "\n",
    "First, write a recursive function `get_head` which takes two arguments: `phrase` and `phrase_type` as input. The `phrase` argument is an NLTK tree representing either an NP or a VP, and `phrase_type` is either `\"N\"` or `\"V\"` for NPs and VPs, respectively. Your function should return the **lemmatized** syntactic head of `phrase`. For example, given the following NLTK syntax tree as input\n",
    "\n",
    "```\n",
    "(NP \n",
    " (DT the) \n",
    " (JJ grey) \n",
    " (NN dogs) \n",
    ")\n",
    "```\n",
    "\n",
    "your function should return `dog`. \n",
    "\n",
    "You can assume that the head is either the right-most token with the appropriate POS `V.*` or `N.*`, or the syntactic head of the right-most child phrase having type `NP.*` or `VP.*` depending on `phrase_type`. This means that you may need to call `get_head` recursively. For example, for \n",
    "\n",
    "```\n",
    "(NP \n",
    " (DT the) \n",
    " (JJ second) \n",
    " (NN incentive) \n",
    " (NN plan)\n",
    ")\n",
    "```\n",
    "\n",
    "you should return `\"plan\"` which is the right-most noun. As another example, consider \n",
    "\n",
    "```\n",
    "(NP \n",
    " (DT the) \n",
    " (JJ blue) \n",
    " (NN bird)\n",
    " (CC and)\n",
    " (NP \n",
    "   (DT the)\n",
    "   (JJ yellow)\n",
    "   (NN butterfly)\n",
    " )\n",
    ")\n",
    "```\n",
    "\n",
    "Here you should return \"`butterfly`\" which is the head of the right-most child NP.\n",
    "\n",
    "If you can't identify a syntactic head, you should return `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatizer.lemmatize(word,pos) returns the lemma for word. \n",
    "# pos should be 'n' for nouns and 'v' for verbs.\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_head(phrase, phrase_type):\n",
    "    '''returns the lemmatized lexical head assuming the provided phrase_type (\"N\",\"V\",etc.)'''\n",
    "    head = None\n",
    "    # your code here\n",
    "        \n",
    "    return head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (get_head(Tree\u001b[38;5;241m.\u001b[39mfromstring(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(NP (DT the) (JJ second) (NN incentive) (NN plan))\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplan\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (get_head(Tree\u001b[38;5;241m.\u001b[39mfromstring(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(NP-SUBJ (NP (DT the) (NNS policies)) (PP (IN of) (NP (NN tomorrow))))\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (get_head(Tree\u001b[38;5;241m.\u001b[39mfromstring(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(VP (VBN offered) (NP (NNS advertisers)))\u001b[39m\u001b[38;5;124m\"\u001b[39m),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert (get_head(Tree.fromstring(\"(NP (DT the) (JJ second) (NN incentive) (NN plan))\"), \"N\") == \"plan\")\n",
    "assert (get_head(Tree.fromstring(\"(NP-SUBJ (NP (DT the) (NNS policies)) (PP (IN of) (NP (NN tomorrow))))\"), \"N\") == \"policy\")\n",
    "assert (get_head(Tree.fromstring(\"(VP (VBN offered) (NP (NNS advertisers)))\"),\"V\") == \"offer\")\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Optional\n",
    "\n",
    "rubric={accuracy:2, quality:1}\n",
    "\n",
    "Next, use the `get_head` function you just wrote in a function which pulls out \"normal\" verb-object relationships, e.g. \"buy\" and \"toy\" in *I bought the toys*. This will involve getting the head of the verb phrase, and the head of its **first** NP child.\n",
    "\n",
    "Note that a single sentence can contain several nested VP's so you should use recursion when implementing `get_short_distance_verb_noun_pairs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_short_distance_verb_noun_pairs(parsed_sent):\n",
    "    '''extracts verb-object pairs from a parsed sentence, \n",
    "       and returns them as a set of (verb,noun) tuples'''\n",
    "    pairs = set()\n",
    "    # your code here\n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now extract all predicate-object pairs from the treebank. You should get at least 2500, but no more than 3200 pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pairs = set()\n",
    "for parsed_sent in treebank.parsed_sents():\n",
    "    total_pairs.update(get_short_distance_verb_noun_pairs(parsed_sent))\n",
    "    \n",
    "print(\"Got %u predicate-object pairs\" % len(total_pairs))\n",
    "assert (\"deduct\",\"expense\") in total_pairs\n",
    "assert 2500 <= len(total_pairs) <= 3200\n",
    "print(\"Success!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
